// More API functions here:
// https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

// the link to your model provided by Teachable Machine export panel
const URL = "./model/";

let model, webcam, labelContainer, maxPredictions, predictText;
let predictValue = [0.0, 0.0, 0.0];

// Load the image model and setup the webcam
async function init() {
    const modelURL = URL + "model.json";
    const metadataURL = URL + "metadata.json";

    // load the model and metadata
    // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
    // or files from your local hard drive
    // Note: the pose library adds "tmImage" object to your window (window.tmImage)
    model = await tmImage.load(modelURL, metadataURL);
    maxPredictions = model.getTotalClasses();



    // Convenience function to setup a webcam
    const flip = true; // whether to flip the webcam
    webcam = new tmImage.Webcam(300, 300, flip); // width, height, flip
    await webcam.setup(); // request access to the webcam
    await webcam.play();
    window.requestAnimationFrame(loop);

    // append elements to the DOM
    var parent = document.getElementById("webcam-container");
    while(parent.firstChild) {
        parent.removeChild(parent.firstChild);
     }
    document.getElementById("webcam-container").appendChild(webcam.canvas);
    labelContainer = document.getElementById("label-container");
    labelText = document.getElementById("label-text");
    for (let i = 0; i < maxPredictions; i++) { // and class labels
        labelContainer.appendChild(document.createElement("div"));
    }

}

async function loop() {
    webcam.update(); // update the webcam frame
    await predict();
    window.requestAnimationFrame(loop);
}

////////////////////////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////////////////////

// run the webcam image through the image model
async function predict() {
    // predict can take in an image, video or canvas html element
    const prediction = await model.predict(webcam.canvas);

    for (let i = 0; i < maxPredictions; i++) {
        const classPrediction =
            prediction[i].className + ": " + prediction[i].probability.toFixed(2);
        labelContainer.childNodes[i].innerHTML = classPrediction;
    }



    if (prediction[0].probability.toFixed(2) >= 0.8) { // ê°€ìœ„ ì¸ì‹
        predictText = "ê°€ìœ„âœŒï¸";
    } else if (prediction[1].probability.toFixed(2) >= 0.8) { // ì£¼ë¨¹ ì¸ì‹
        predictText = "ë°”ìœ„âœŠ";
    } else if (prediction[2].probability.toFixed(2) >= 0.8) { // ë³´ ì¸ì‹
        predictText = "ë³´ğŸ–ï¸";
    } else { // ì¸ì‹ ë¶ˆê°€
        predictText = "???";
    }

    labelText.innerHTML = 'ë‹¹ì‹ ì€ ' + predictText + 'ë¥¼ ë‚´ì…¨êµ°ìš”!';
    answeringText = document.getElementById("answering-text");


    if (prediction[0].probability.toFixed(2) >= 0.8){ // ê°€ìœ„ë¥¼ ëƒˆì„ ê²½ìš°
        answeringText.innerHTML = 'AIëŠ” ì£¼ë¨¹ì„ ëƒˆìŠµë‹ˆë‹¤!'
    }

    else if (prediction[1].probability.toFixed(2) >= 0.8){ // ì£¼ë¨¹ì„ ëƒˆì„ ê²½ìš°
        answeringText.innerHTML = 'AIëŠ” ë³´ë¥¼ ëƒˆìŠµë‹ˆë‹¤!'
    }
    
    else if (prediction[2].probability.toFixed(2) >= 0.8){ // ë³´ë¥¼ ëƒˆì„ ê²½ìš°
        answeringText.innerHTML = 'AIëŠ” ê°€ìœ„ë¥¼ ëƒˆìŠµë‹ˆë‹¤!'
    }

    else { // ì¸ì‹ ì•ˆë¨
        answeringText.innerHTML = "ì •í™•íˆ ê°€ìœ„/ë°”ìœ„/ë³´ë¥¼ ë‚´ì£¼ì„¸ìš”!"
    }
    
}